{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c6758699-9add-46ff-b7f9-724314c2ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "import dateutil\n",
    "import statistics"
   ]
  },
  {
   "source": [
    "## Preprocessing Classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Heart Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "2655fb42-9f65-41b1-a530-5665dae93ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess_Heart:\n",
    "\n",
    "  def MergeHeartData(path):\n",
    "    #storedDataPAth = '../merged/'\n",
    "    newPath = 'merged/'\n",
    "    if not os.path.exists(newPath):\n",
    "      merged_path = os.mkdir(newPath)\n",
    "    else:\n",
    "      merged_path = newPath\n",
    "\n",
    "\n",
    "    merged_files = list()\n",
    "    userFolders = sorted([userFolder for userFolder in glob.glob(path + '/**') if not userFolder.startswith('.') and 'merged' not in userFolder])\n",
    "    users = [person for person in os.listdir(path)]\n",
    "    feature = 'heart'\n",
    "    #print(userFolders)\n",
    "    for user in users:\n",
    "      data_folder = user + '/'\n",
    "      if not os.path.exists(merged_path + data_folder):\n",
    "        os.mkdir(merged_path + data_folder)\n",
    "      else:\n",
    "        data_path = merged_path + data_folder\n",
    "      result = list()\n",
    "      files = [feature_file for feature_file in glob.glob(path + user + '/' + feature + '/*.json')]\n",
    "      #print(files)\n",
    "      for file in files:\n",
    "        #print('')\n",
    "        with open(file, \"r\") as infile:\n",
    "            \n",
    "          result.append(json.load(infile))\n",
    "            #print(result)\n",
    "          \n",
    "      #print(result)\n",
    "      #print(merged_path)\n",
    "      with open(merged_path + data_folder +  feature  + \".json\", \"w\") as merged_file:\n",
    "        #print(merged_file)\n",
    "        json.dump(result, merged_file)\n",
    "        #print(type(result[0]))\n",
    "       \n",
    "          \n",
    "\n",
    "  def ReOrder(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.')])\n",
    "    #print(mergedUsers)\n",
    "    \n",
    "    for mergedUser in mergedUsers:\n",
    "      files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'heart' in feature_file]\n",
    "      #print(files)\n",
    "      for file in files:\n",
    "        with open(file, \"r\") as unsorted_file:\n",
    "          json_file = json.load(unsorted_file)\n",
    "          if 'heart' in file:\n",
    "            sorted_file = sorted(json_file, key = lambda i: i['activities-heart'][0]['dateTime'])\n",
    "        with open(file, \"w\") as unsorted_file:\n",
    "          json.dump(sorted_file, unsorted_file)\n",
    "\n",
    "  #def DeleteDuplicates():\n",
    "  # # Re-Index\n",
    "  def toDataFrame(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.')])\n",
    "    hearts = []\n",
    "    print(mergedUsers)\n",
    "    for mergedUser in mergedUsers:\n",
    "        files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'heart' in feature_file]\n",
    "        for file in files:\n",
    "            heart_dicts = []\n",
    "            with open(file, \"r\") as raw_file:\n",
    "                json_file = json.load(raw_file)\n",
    "                if 'heart' in file:\n",
    "                    heart_dicts = [pd.DataFrame.from_dict(pd.json_normalize(json_file[i]['activities-heart-intraday']['dataset'])) for i in range(len(json_file)) if len(json_file[i]['activities-heart-intraday']['dataset']) > 0]\n",
    "                    #print(len(heart_dicts), len(json_file))\n",
    "                    for i in range(len(heart_dicts)):\n",
    "                      date = json_file[i]['activities-heart'][0]['dateTime']\n",
    "                      heart_dicts[i] = heart_dicts[i].assign(time = lambda x: (date + ' ' + x['time']))\n",
    "                      heart_dicts[i].rename(columns = {'time':'dateTime'}, inplace = True)\n",
    "                    hearts.append(heart_dicts)\n",
    "    return hearts\n",
    "\n",
    "  def extractData(data, startTime, endTime):\n",
    "    #pandas.to_datetime\n",
    "    users = []\n",
    "    for user in data:\n",
    "      for i in range(len(user)):\n",
    "        user[i] = user[i].assign(dateTime = lambda x: (pd.to_datetime(user[i]['dateTime'], format=\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    data_windows = []\n",
    "    for user in range(len(data)) :\n",
    "        participant_windows = []\n",
    "        for day in data[user]:\n",
    "          half = day[day['dateTime'] >= pd.to_datetime(startTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          final = half[half['dateTime'] <= pd.to_datetime(endTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          participant_windows.append(final)\n",
    "        data_windows.append(participant_windows)\n",
    "    return data_windows\n"
   ]
  },
  {
   "source": [
    "### Step PrePRocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess_Steps:\n",
    "  def MergeStepData(path):\n",
    "    #storedDataPAth = '../merged/'\n",
    "    newPath = 'merged/'\n",
    "    if not os.path.exists(newPath):\n",
    "      merged_path = os.mkdir(newPath)\n",
    "    else:\n",
    "      merged_path = newPath\n",
    "\n",
    "\n",
    "    merged_files = list()\n",
    "    userFolders = sorted([userFolder for userFolder in glob.glob(path + '/**') if not userFolder.startswith('.') and 'merged' not in userFolder])\n",
    "    users = [person for person in os.listdir(path)]\n",
    "    feature = 'steps'\n",
    "    #print(userFolders)\n",
    "    for user in users:\n",
    "      data_folder = user + '/'\n",
    "      if not os.path.exists(merged_path + data_folder):\n",
    "        os.mkdir(merged_path + data_folder)\n",
    "      else:\n",
    "        data_path = merged_path + data_folder\n",
    "      result = list()\n",
    "      files = [feature_file for feature_file in glob.glob(path + user + '/' + feature + '/*.json')]\n",
    "      #print(files)\n",
    "      for file in files:\n",
    "        #print('')\n",
    "        with open(file, \"r\") as infile:\n",
    "            \n",
    "          result.append(json.load(infile))\n",
    "            #print(result)\n",
    "          \n",
    "      #print(result)\n",
    "      #print(merged_path)\n",
    "      with open(merged_path + data_folder +  feature  + \".json\", \"w\") as merged_file:\n",
    "        #print(merged_file)\n",
    "        json.dump(result, merged_file)\n",
    "   \n",
    "  def ReOrder(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.') and 'merged' in mergedUser])\n",
    "    \n",
    "    for mergedUser in mergedUsers:\n",
    "      files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'step' in feature_file]\n",
    "      for file in files:\n",
    "        with open(file, \"r\") as unsorted_file:\n",
    "          json_file = json.load(unsorted_file)\n",
    "          if 'steps' in file:\n",
    "            sorted_file = sorted(json_file, key = lambda i: i['activities-steps'][0]['dateTime'])\n",
    "        with open(file, \"w\") as unsorted_file:\n",
    "          json.dump(sorted_file, unsorted_file)\n",
    "\n",
    "  #def DeleteDuplicates():\n",
    "  #  Re-Index\n",
    "  def toDataFrame(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.')])\n",
    "    steps = []\n",
    "    #print(mergedUsers)\n",
    "    for mergedUser in mergedUsers:\n",
    "        files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'steps' in feature_file]\n",
    "        for file in files:\n",
    "            step_dicts = []\n",
    "            with open(file, \"r\") as raw_file:\n",
    "                json_file = json.load(raw_file)\n",
    "                if 'step' in file:\n",
    "                    step_dicts = [pd.DataFrame.from_dict(pd.json_normalize(json_file[i]['activities-steps-intraday']['dataset'])) for i in range(len(json_file)) if len(json_file[i]['activities-steps-intraday']['dataset']) > 0]\n",
    "                    #print(len(heart_dicts), len(json_file))\n",
    "                    for i in range(len(step_dicts)):\n",
    "                      date = json_file[i]['activities-steps'][0]['dateTime']\n",
    "                      step_dicts[i] = step_dicts[i].assign(time = lambda x: (date + ' ' + x['time']))\n",
    "                      step_dicts[i].rename(columns = {'time':'dateTime'}, inplace = True)\n",
    "                    steps.append(step_dicts)\n",
    "    return steps\n",
    "\n",
    " def extractData(data, startTime, endTime):\n",
    "    #pandas.to_datetime\n",
    "    users = []\n",
    "    for user in data:\n",
    "      for i in range(len(user)):\n",
    "        user[i] = user[i].assign(dateTime = lambda x: (pd.to_datetime(user[i]['dateTime'], format=\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    data_windows = []\n",
    "    for user in range(len(data)) :\n",
    "        participant_windows = []\n",
    "        for day in data[user]:\n",
    "          half = day[day['dateTime'] >= pd.to_datetime(startTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          final = half[half['dateTime'] <= pd.to_datetime(endTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          participant_windows.append(final)\n",
    "        data_windows.append(participant_windows)\n",
    "    return data_windows"
   ]
  },
  {
   "source": [
    "### Sleep PreProcessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess_Sleep:\n",
    "\n",
    "  def MergeSleepData(path):\n",
    "    #storedDataPAth = '../merged/'\n",
    "    newPath = 'merged/'\n",
    "    if not os.path.exists(newPath):\n",
    "      merged_path = os.mkdir(newPath)\n",
    "    else:\n",
    "      merged_path = newPath\n",
    "\n",
    "\n",
    "    merged_files = list()\n",
    "    userFolders = sorted([userFolder for userFolder in glob.glob(path + '/**') if not userFolder.startswith('.') and 'merged' not in userFolder])\n",
    "    users = [person for person in os.listdir(path)]\n",
    "    feature = 'sleep'\n",
    "    #print(userFolders)\n",
    "    for user in users:\n",
    "      data_folder = user + '/'\n",
    "      if not os.path.exists(merged_path + data_folder):\n",
    "        os.mkdir(merged_path + data_folder)\n",
    "      else:\n",
    "        data_path = merged_path + data_folder\n",
    "      result = list()\n",
    "      files = [feature_file for feature_file in glob.glob(path + user + '/' + feature + '/*.json')]\n",
    "      #print(files)\n",
    "      for file in files:\n",
    "        #print('')\n",
    "        with open(file, \"r\") as infile:\n",
    "            \n",
    "          result.append(json.load(infile))\n",
    "            #print(result)\n",
    "          \n",
    "      #print(result)\n",
    "      #print(merged_path)\n",
    "      with open(merged_path + data_folder +  feature  + \".json\", \"w\") as merged_file:\n",
    "        #print(merged_file)\n",
    "        json.dump(result, merged_file)\n",
    "          #print(type(result[0]))\n",
    "       \n",
    "          \n",
    "\n",
    "  def ReOrder(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.') and 'merged' in mergedUser])\n",
    "    \n",
    "    for mergedUser in mergedUsers:\n",
    "      files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'sleep' in feature_file]\n",
    "      for file in files:\n",
    "        with open(file, \"r\") as unsorted_file:\n",
    "          json_file = json.load(unsorted_file)\n",
    "          if 'sleep' in file:\n",
    "            json_files = [file for file in json_file if len(file['sleep']) > 0]\n",
    "            sorted_file = sorted(json_files, key = lambda i: i['sleep'][0]['dateOfSleep'])\n",
    "        with open(file, \"w\") as unsorted_file:\n",
    "          json.dump(sorted_file, unsorted_file)\n",
    "\n",
    "  #def DeleteDuplicates():\n",
    "  # # Re-Index\n",
    "  def toDataFrame(path):\n",
    "    mergedUsers = sorted([mergedUser for mergedUser in glob.glob('merged/' + '/**') if not mergedUser.startswith('.') and 'merged' in mergedUser])\n",
    "    sleeps = []\n",
    "    for mergedUser in mergedUsers:\n",
    "        files = [feature_file for feature_file in glob.glob(mergedUser + '/*.json') if 'sleep' in feature_file]\n",
    "        for file in files:\n",
    "            sleep_dicts = []\n",
    "            with open(file, \"r\") as raw_file:\n",
    "                json_file = json.load(raw_file)\n",
    "                if 'sleep' in file:\n",
    "                    sleep_dicts = list()\n",
    "                    for i in range(len(json_file)):\n",
    "                    #print(len(json_file[i]['sleep']))\n",
    "                        dailySleep = json_file[i]['sleep'][0]['minuteData']\n",
    "                        if len(json_file[i]['sleep']) > 1:\n",
    "                            j = 1\n",
    "                            for j in range(len(json_file[i]['sleep'])):\n",
    "                                dailySleep.extend(json_file[i]['sleep'][j]['minuteData'])\n",
    "                        sleep_dicts.append(pd.DataFrame.from_dict(pd.json_normalize(sorted(dailySleep, key = lambda x: x['dateTime']))))\n",
    "                    for i in range(len(sleep_dicts)):\n",
    "                      date = json_file[i]['sleep'][0]['dateOfSleep']\n",
    "                      sleep_dicts[i] = sleep_dicts[i].assign(dateTime = lambda x: (date + ' ' + x['dateTime']))\n",
    "                    sleeps.append(sleep_dicts)\n",
    "    return sleeps\n",
    "\n",
    "  def extractData(data, startTime, endTime):\n",
    "    #pandas.to_datetime\n",
    "    users = []\n",
    "    for user in data:\n",
    "      for i in range(len(user)):\n",
    "        user[i] = user[i].assign(dateTime = lambda x: (pd.to_datetime(user[i]['dateTime'], format=\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    data_windows = []\n",
    "    for user in range(len(data)) :\n",
    "        participant_windows = []\n",
    "        for day in data[user]:\n",
    "          half = day[day['dateTime'] >= pd.to_datetime(startTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          final = half[half['dateTime'] <= pd.to_datetime(endTime, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "          participant_windows.append(final)\n",
    "        data_windows.append(participant_windows)\n",
    "    return data_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ph1 = PreProcess_Heart\n",
    "pst2 = PreProcess_Steps\n",
    "psl3 = PreProcess_Sleep\n",
    "path = \"20210602/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1.MergeHeartData(path)\n",
    "pst2.MergeStepData(path)\n",
    "psl3.MergeSleepData(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1.ReOrder(path)\n",
    "pst2.ReOrder(path)\n",
    "psl3.ReOrder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['merged/CR2002', 'merged/CR2003', 'merged/CR2005', 'merged/CR2006', 'merged/CR2007', 'merged/CR2010', 'merged/CR2012', 'merged/CR2014', 'merged/CR2016', 'merged/CR2017', 'merged/CR2018', 'merged/CR2019', 'merged/CR2020', 'merged/CR2021', 'merged/CR2022', 'merged/CR2023', 'merged/CR2024']\n"
     ]
    }
   ],
   "source": [
    "heart_Dfs = ph1.toDataFrame(path)\n",
    "step_Dfs = pst2.toDataFrame(path)\n",
    "sleep_Dfs = psl3.toDataFrame(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "                  dateTime  value\n",
       "  717  2021-01-26 12:00:00     69\n",
       "  718  2021-01-26 12:01:00     71\n",
       "  719  2021-01-26 12:02:00     71\n",
       "  720  2021-01-26 12:03:00     68\n",
       "  721  2021-01-26 12:04:00     65\n",
       "  ...                  ...    ...\n",
       "  1397 2021-01-26 23:55:00     68\n",
       "  1398 2021-01-26 23:56:00     68\n",
       "  1399 2021-01-26 23:57:00     69\n",
       "  1400 2021-01-26 23:58:00     72\n",
       "  1401 2021-01-26 23:59:00     72\n",
       "  \n",
       "  [685 rows x 2 columns],\n",
       "                  dateTime  value\n",
       "  0    2021-01-27 00:00:00     72\n",
       "  1    2021-01-27 00:01:00     70\n",
       "  2    2021-01-27 00:02:00     70\n",
       "  3    2021-01-27 00:03:00     70\n",
       "  4    2021-01-27 00:04:00     70\n",
       "  ...                  ...    ...\n",
       "  1341 2021-01-27 23:55:00     85\n",
       "  1342 2021-01-27 23:56:00     80\n",
       "  1343 2021-01-27 23:57:00     82\n",
       "  1344 2021-01-27 23:58:00     83\n",
       "  1345 2021-01-27 23:59:00     83\n",
       "  \n",
       "  [1346 rows x 2 columns],\n",
       "                  dateTime  value\n",
       "  0    2021-01-28 00:00:00     81\n",
       "  1    2021-01-28 00:01:00     81\n",
       "  2    2021-01-28 00:02:00     78\n",
       "  3    2021-01-28 00:03:00     77\n",
       "  4    2021-01-28 00:04:00     80\n",
       "  ...                  ...    ...\n",
       "  1425 2021-01-28 23:55:00     71\n",
       "  1426 2021-01-28 23:56:00     71\n",
       "  1427 2021-01-28 23:57:00     71\n",
       "  1428 2021-01-28 23:58:00     72\n",
       "  1429 2021-01-28 23:59:00     72\n",
       "  \n",
       "  [1430 rows x 2 columns],\n",
       "                  dateTime  value\n",
       "  0    2021-01-29 00:00:00     71\n",
       "  1    2021-01-29 00:01:00     72\n",
       "  2    2021-01-29 00:02:00     72\n",
       "  3    2021-01-29 00:03:00     72\n",
       "  4    2021-01-29 00:04:00     73\n",
       "  ...                  ...    ...\n",
       "  1402 2021-01-29 23:55:00     65\n",
       "  1403 2021-01-29 23:56:00     65\n",
       "  1404 2021-01-29 23:57:00     65\n",
       "  1405 2021-01-29 23:58:00     67\n",
       "  1406 2021-01-29 23:59:00     66\n",
       "  \n",
       "  [1407 rows x 2 columns],\n",
       "                  dateTime  value\n",
       "  0    2021-01-30 00:00:00     65\n",
       "  1    2021-01-30 00:01:00     64\n",
       "  2    2021-01-30 00:02:00     63\n",
       "  3    2021-01-30 00:03:00     62\n",
       "  4    2021-01-30 00:04:00     62\n",
       "  ...                  ...    ...\n",
       "  1429 2021-01-30 23:55:00     68\n",
       "  1430 2021-01-30 23:56:00     69\n",
       "  1431 2021-01-30 23:57:00     68\n",
       "  1432 2021-01-30 23:58:00     68\n",
       "  1433 2021-01-30 23:59:00     69\n",
       "  \n",
       "  [1434 rows x 2 columns],\n",
       "                  dateTime  value\n",
       "  0    2021-01-31 00:00:00     71\n",
       "  1    2021-01-31 00:01:00     69\n",
       "  2    2021-01-31 00:02:00     71\n",
       "  3    2021-01-31 00:04:00     68\n",
       "  4    2021-01-31 00:05:00     69\n",
       "  ...                  ...    ...\n",
       "  1012 2021-01-31 16:56:00    120\n",
       "  1013 2021-01-31 16:57:00    120\n",
       "  1014 2021-01-31 16:58:00    115\n",
       "  1015 2021-01-31 16:59:00    116\n",
       "  1016 2021-01-31 17:00:00    118\n",
       "  \n",
       "  [1017 rows x 2 columns],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []],\n",
       " [Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [dateTime, value]\n",
       "  Index: []]]"
      ]
     },
     "metadata": {},
     "execution_count": 385
    }
   ],
   "source": [
    "ph1.extractData(heart_Dfs, '2021-01-26 12:00:00', '2021-01-31 17:00:00')"
   ]
  },
  {
   "source": [
    "### Step Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step_Features:\n",
    "\n",
    "  def numOfSteps(step_data, window_size, value):\n",
    "    new_data = PreProcess.extractData(step_data, window_size, value)\n",
    "    columns = ['Total Steps', 'Mean', 'Median', 'St Dev']\n",
    "    user_dfs = []\n",
    "    for participant_data in range(len(new_data)):\n",
    "      user_rows = []\n",
    "      for day in range(len(new_data[participant_data])):\n",
    "        for window in range(len(new_data[participant_data][day])):\n",
    "            #print(new_data[0][0][0]['value'].values)\n",
    "            total = sum(new_data[participant_data][day][window]['value'].values)\n",
    "            avg = statistics.mean(new_data[participant_data][day][window]['value'].values)\n",
    "            median = statistics.median(new_data[participant_data][day][window]['value'].values)\n",
    "            stdev = statistics.stdev(new_data[participant_data][day][window]['value'].values)\n",
    "            features = [total, avg, median, stdev]\n",
    "            user_rows.append(features)\n",
    "      user_dfs.append(pd.DataFrame(user_rows, columns=columns))\n",
    "    return user_dfs   \n",
    "\n",
    "  def activeEntropy(step_data, window_size, value):\n",
    "    print('steps')\n",
    "  \n",
    "  def inactiveEntropy(step_data, window_size, value):\n",
    "    print('steps')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = Step_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_results = test1.numOfSteps(step_dfs, 5, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Total Steps  Mean  Median     St Dev\n",
       "0              0     0     0.0   0.000000\n",
       "1           2564     8     0.0  17.916473\n",
       "2           6821    22    16.0  23.366643\n",
       "3           3673    12     0.0  20.469489\n",
       "4            807     3     0.0   9.695360\n",
       "..           ...   ...     ...        ...\n",
       "130           13     0     0.0   0.000000\n",
       "131         1315     4     0.0  11.532563\n",
       "132         2537     8     0.0  15.588457\n",
       "133         1336     4     0.0  11.090537\n",
       "134          558     2     0.0   7.549834\n",
       "\n",
       "[135 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total Steps</th>\n      <th>Mean</th>\n      <th>Median</th>\n      <th>St Dev</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2564</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>17.916473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6821</td>\n      <td>22</td>\n      <td>16.0</td>\n      <td>23.366643</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3673</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>20.469489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>807</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>9.695360</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>13</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>1315</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>11.532563</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>2537</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>15.588457</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>1336</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>11.090537</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>558</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>7.549834</td>\n    </tr>\n  </tbody>\n</table>\n<p>135 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "step_results[0]"
   ]
  },
  {
   "source": [
    "### Heart Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heart_Features:\n",
    "  def heartCalc(heart_data, window_size, value):\n",
    "    new_data = PreProcess.extractData(heart_data, window_size, value)\n",
    "    columns = [ 'Mean', 'Median', 'St Dev']\n",
    "    user_dfs = []\n",
    "    for participant_data in range(len(new_data)):\n",
    "      user_rows = []\n",
    "      for day in range(len(new_data[participant_data])):\n",
    "        for window in range(len(new_data[participant_data][day])):\n",
    "            #print(new_data[0][0][0]['value'].values\n",
    "            avg = statistics.mean(new_data[participant_data][day][window]['value'].values)\n",
    "            median = statistics.median(new_data[participant_data][day][window]['value'].values)\n",
    "            if len(new_data[participant_data][day][window]['value'].values) > 1:\n",
    "                stdev = statistics.stdev(new_data[participant_data][day][window]['value'].values)\n",
    "            else: \n",
    "                stdev = '-'\n",
    "            features = [avg, median, stdev]\n",
    "            user_rows.append(features)\n",
    "      user_dfs.append(pd.DataFrame(user_rows, columns=columns))\n",
    "    return user_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_test = Heart_Features\n",
    "heart_results = heart_test.heartCalc(heart_dfs, 5, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "len(heart_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Mean  Median     St Dev\n",
       "0     84    83.0   8.831761\n",
       "1     82    81.0   6.480741\n",
       "2     74    74.0   3.872983\n",
       "3     68    70.0   2.236068\n",
       "4     64    65.0   2.000000\n",
       "5     77    73.0  13.453624\n",
       "6     74    73.0   5.567764\n",
       "7     80    79.0   7.141428\n",
       "8     78    78.0   9.000000\n",
       "9     71    72.0   2.449490\n",
       "10    77    75.0   6.557439\n",
       "11    83    81.0   6.480741\n",
       "12    82    82.0   6.082763\n",
       "13    73    73.0   4.472136\n",
       "14    66    67.0   3.000000\n",
       "15    77    75.0  15.099669\n",
       "16    92    89.0   9.273618\n",
       "17    89    85.5  10.392305\n",
       "18    74    75.0   4.795832\n",
       "19    69    69.0   2.828427\n",
       "20    68    66.0   6.403124\n",
       "21    96    92.0  12.806248\n",
       "22    83    81.0   6.403124\n",
       "23    74    74.0   4.358899\n",
       "24    69    69.0   3.316625\n",
       "25    77    76.0  13.784049\n",
       "26   102    98.0  14.317821\n",
       "27    93    91.0   7.810250\n",
       "28    78    77.0   3.741657\n",
       "29    69    69.0   2.236068\n",
       "30    74    71.0  12.727922\n",
       "31    82    80.0   7.211103\n",
       "32    83    82.0   8.660254\n",
       "33    76    75.0   7.071068\n",
       "34    73    74.0   4.000000\n",
       "35    76    72.0  11.357817\n",
       "36    80    78.0   8.426150\n",
       "37    76    75.0   5.099020\n",
       "38    75    75.0   2.645751\n",
       "39    68    68.0   3.464102\n",
       "40    65    65.0   5.656854"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Median</th>\n      <th>St Dev</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84</td>\n      <td>83.0</td>\n      <td>8.831761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>82</td>\n      <td>81.0</td>\n      <td>6.480741</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74</td>\n      <td>74.0</td>\n      <td>3.872983</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>68</td>\n      <td>70.0</td>\n      <td>2.236068</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>64</td>\n      <td>65.0</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>77</td>\n      <td>73.0</td>\n      <td>13.453624</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>74</td>\n      <td>73.0</td>\n      <td>5.567764</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>80</td>\n      <td>79.0</td>\n      <td>7.141428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>78</td>\n      <td>78.0</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>71</td>\n      <td>72.0</td>\n      <td>2.449490</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>77</td>\n      <td>75.0</td>\n      <td>6.557439</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>83</td>\n      <td>81.0</td>\n      <td>6.480741</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>82</td>\n      <td>82.0</td>\n      <td>6.082763</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>73</td>\n      <td>73.0</td>\n      <td>4.472136</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>66</td>\n      <td>67.0</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>77</td>\n      <td>75.0</td>\n      <td>15.099669</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>92</td>\n      <td>89.0</td>\n      <td>9.273618</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>89</td>\n      <td>85.5</td>\n      <td>10.392305</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>74</td>\n      <td>75.0</td>\n      <td>4.795832</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>69</td>\n      <td>69.0</td>\n      <td>2.828427</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>68</td>\n      <td>66.0</td>\n      <td>6.403124</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>96</td>\n      <td>92.0</td>\n      <td>12.806248</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>83</td>\n      <td>81.0</td>\n      <td>6.403124</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>74</td>\n      <td>74.0</td>\n      <td>4.358899</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>69</td>\n      <td>69.0</td>\n      <td>3.316625</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>77</td>\n      <td>76.0</td>\n      <td>13.784049</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>102</td>\n      <td>98.0</td>\n      <td>14.317821</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>93</td>\n      <td>91.0</td>\n      <td>7.810250</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>78</td>\n      <td>77.0</td>\n      <td>3.741657</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>69</td>\n      <td>69.0</td>\n      <td>2.236068</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>74</td>\n      <td>71.0</td>\n      <td>12.727922</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>82</td>\n      <td>80.0</td>\n      <td>7.211103</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>83</td>\n      <td>82.0</td>\n      <td>8.660254</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>76</td>\n      <td>75.0</td>\n      <td>7.071068</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>73</td>\n      <td>74.0</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>76</td>\n      <td>72.0</td>\n      <td>11.357817</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>80</td>\n      <td>78.0</td>\n      <td>8.426150</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>76</td>\n      <td>75.0</td>\n      <td>5.099020</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>75</td>\n      <td>75.0</td>\n      <td>2.645751</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>68</td>\n      <td>68.0</td>\n      <td>3.464102</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>65</td>\n      <td>65.0</td>\n      <td>5.656854</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "heart_results[4]"
   ]
  },
  {
   "source": [
    "### Sleep Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sleep_Features:\n",
    "  def heartCalc(heart_data, window_size, value):\n",
    "    new_data = PreProcess.extractData(heart_data, window_size, value)\n",
    "    columns = ['Duration', 'Sleep Regularity']\n",
    "    user_dfs = []\n",
    "    for participant_data in range(len(new_data)):\n",
    "      user_rows = []\n",
    "      for day in range(len(new_data[participant_data])):\n",
    "        for window in range(len(new_data[participant_data][day])):\n",
    "            #print(new_data[0][0][0]['value'].values\n",
    "            avg = statistics.mean(new_data[participant_data][day][window]['value'].values)\n",
    "            median = statistics.median(new_data[participant_data][day][window]['value'].values)\n",
    "            if len(new_data[participant_data][day][window]['value'].values) > 1:\n",
    "                stdev = statistics.stdev(new_data[participant_data][day][window]['value'].values)\n",
    "            else: \n",
    "                stdev = '-'\n",
    "            features = [avg, median, stdev]\n",
    "            user_rows.append(features)\n",
    "      user_dfs.append(pd.DataFrame(user_rows, columns=columns))\n",
    "    return user_dfs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe47a2f740d7a0114f44ddebc6602e72ddf4a2c68faec1c3fe8ea7163af518e3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}